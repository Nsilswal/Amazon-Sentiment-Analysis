{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nycwhmKu2s5"
      },
      "source": [
        "# Sentiment Analysis of Amazon Reviews using Discriminative Models Trained on Synthetic Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue43YZKau2s9"
      },
      "source": [
        "<h2>1. Preprocessing Data</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Packages"
      ],
      "metadata": {
        "id": "nFxLiJJbTdet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-plot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aHYfny4vC-q",
        "outputId": "9c3acdd0-192f-4e62-9a6d-0947a2f0b1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.8/dist-packages (0.3.7)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T06:17:29.697126Z",
          "start_time": "2020-04-26T06:17:28.603446Z"
        },
        "id": "92T7QcsTu2s9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scikitplot as skplt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer,ToktokTokenizer\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,recall_score,precision_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from string import punctuation\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import os\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS8zCo3xu2s_"
      },
      "source": [
        "<h4>Read the data</h4>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeIt4LX1Lwhx",
        "outputId": "3e5cdc00-f4d5-4725-e8f8-7c9bbe0546ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/NLP Final Project/Womens Clothing E-Commerce Reviews.csv\""
      ],
      "metadata": {
        "id": "p1ncbYG7L9z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:08.888627Z",
          "start_time": "2020-04-26T05:14:08.524413Z"
        },
        "id": "G-7CvQUFu2s_"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:09.038168Z",
          "start_time": "2020-04-26T05:14:08.916146Z"
        },
        "id": "d2rluK7su2tB"
      },
      "outputs": [],
      "source": [
        "data = data[['Review Text','Recommended IND']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeWibfzGu2tB"
      },
      "source": [
        "<h4>Renaming Columns</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:09.291864Z",
          "start_time": "2020-04-26T05:14:09.165348Z"
        },
        "id": "lV5XWR7Cu2tC"
      },
      "outputs": [],
      "source": [
        "data.rename(columns={'Review Text':'review_text','Recommended IND':'recommended'},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm-0vyFlu2tC"
      },
      "source": [
        "<h4>Checking and Handling Missing Values</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:09.508952Z",
          "start_time": "2020-04-26T05:14:09.394777Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfg2qqZYu2tC",
        "outputId": "935e7fc6-be46-4754-b471-d22b86e4ffab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_text    845\n",
              "recommended      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3oLmDonu2tC"
      },
      "source": [
        "<div style=\"text-align:justify\">From 2 variable above, review_text have so many missing values. Removing those missing values can lead to lack of information from the data, so instead of remove the data, let's fill missing values with blank space.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:09.627473Z",
          "start_time": "2020-04-26T05:14:09.513937Z"
        },
        "id": "_ts6g4A-u2tD"
      },
      "outputs": [],
      "source": [
        "data['review_text'] = data['review_text'].fillna(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:09.768425Z",
          "start_time": "2020-04-26T05:14:09.633924Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpBKfkEiu2tD",
        "outputId": "5c2a8135-496e-45a5-bde5-032fa1582e12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_text    0\n",
              "recommended    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:09.91453Z",
          "start_time": "2020-04-26T05:14:09.772928Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn8IBzTju2tD",
        "outputId": "d2521566-d331-4344-94e1-f7b3cbeea95c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_text    object\n",
              "recommended     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOgkDgWBu2tD"
      },
      "source": [
        "<h2>Exploratory Data Analysis (EDA)</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgJCEvG6u2tD"
      },
      "source": [
        "<h4>Renaming Target Variable Values</h4>\n",
        "Instead of using 0 and 1 as values of target variable, we can use more appropiate values like \"Not Recommended\" and \"Recommended\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:10.036346Z",
          "start_time": "2020-04-26T05:14:09.917531Z"
        },
        "id": "FBS7mfyEu2tE"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"recommended\"] == 0, \"recommended\"] = \"Not Recommended\" # 0 -> Not Recommended\n",
        "data.loc[data[\"recommended\"] == 1, \"recommended\"] = \"Recommended\" # 1 -> Recommended"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84SUve5fwFxv",
        "outputId": "6ad25a85-23c5-4daa-e165-cc72619aa68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CEJPi6Xu2tG"
      },
      "source": [
        "<h2>Text Mining</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2mbBz65u2tG"
      },
      "source": [
        "<div style=\"text-align:justify\">In this text mining process we will exploring and analyzing unstructured text data</div>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:11.89157Z",
          "start_time": "2020-04-26T05:14:11.786323Z"
        },
        "id": "hb3boBpEu2tG"
      },
      "outputs": [],
      "source": [
        "tokenizer=ToktokTokenizer()\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_text = data['review_text']\n",
        "target = data['recommended']"
      ],
      "metadata": {
        "id": "tCbwXX9CXi2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTymM0Dhu2tG"
      },
      "source": [
        "<h4>Expanding Contraction</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:12.169386Z",
          "start_time": "2020-04-26T05:14:12.033267Z"
        },
        "id": "VKTQgYqBu2tH"
      },
      "outputs": [],
      "source": [
        "contractions_dict = {     \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I had\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"iit will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they had\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:29.723681Z",
          "start_time": "2020-04-26T05:14:12.175795Z"
        },
        "id": "S6mh5U60u2tH"
      },
      "outputs": [],
      "source": [
        "def expand_contractions(text, contractions_dict):\n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
        "                                      flags=re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contractions_dict.get(match) \\\n",
        "            if contractions_dict.get(match) \\\n",
        "            else contractions_dict.get(match.lower())\n",
        "        expanded_contraction = expanded_contraction\n",
        "        return expanded_contraction\n",
        "\n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "def cons(text):\n",
        "    text=expand_contractions(text,contractions_dict)\n",
        "    return text\n",
        "\n",
        "main_text = main_text.apply(cons)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AhEOvrZu2tH"
      },
      "source": [
        "<h4>To lowercase</h4><br>\n",
        "Change all uppercase character to be lowercase character. For example \"Pretty\" to be \"pretty\" or \"BEAUTY\" to be \"beauty\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:46.152983Z",
          "start_time": "2020-04-26T05:14:29.727771Z"
        },
        "id": "UyprHdJgu2tI"
      },
      "outputs": [],
      "source": [
        "#Tolowercase\n",
        "def to_lower(text):\n",
        "    return ' '.join([w.lower() for w in word_tokenize(text)])\n",
        "\n",
        "main_text = main_text.apply(to_lower)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvveGa_Su2tI"
      },
      "source": [
        "<h4>Remove Special Character and Punctuation</h4><br>\n",
        "Removing all special character like .?/@# etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:47.245015Z",
          "start_time": "2020-04-26T05:14:46.155486Z"
        },
        "id": "0wzpczVqu2tI"
      },
      "outputs": [],
      "source": [
        "#Define function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "def strip_punctuation(s):\n",
        "    return ''.join(c for c in s if c not in punctuation)\n",
        "\n",
        "main_text = main_text.apply(remove_special_characters)\n",
        "main_text = main_text.apply(strip_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V09F9pGvu2tI"
      },
      "source": [
        "<h4>Replace Elongated Words</h4><br>\n",
        "Replace all elongated words with appropriate words. For example \"soooooo\" to be \"so\" or \"looooong\" to be \"long\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXKyCaPcwheS",
        "outputId": "14497ab0-8e24-4f82-c70a-01036513b77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:51.501246Z",
          "start_time": "2020-04-26T05:14:47.246979Z"
        },
        "id": "_mxDeeu4u2tI"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def replaceElongated(word):\n",
        "    repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "    repl = r'\\1\\2\\3'\n",
        "    if wordnet.synsets(word):\n",
        "        return word\n",
        "    repl_word = repeat_regexp.sub(repl, word)\n",
        "    if repl_word != word:      \n",
        "        return replaceElongated(repl_word)\n",
        "    else:       \n",
        "        return repl_word\n",
        "main_text = main_text.apply(replaceElongated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OArPnTIu2tI"
      },
      "source": [
        "<h4>Tokenization</h4><br>\n",
        "Tokenization is splitting sentences into smaller unit, such as terms or word. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:52.132433Z",
          "start_time": "2020-04-26T05:14:51.503752Z"
        },
        "id": "tF09jOEMu2tI"
      },
      "outputs": [],
      "source": [
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "main_text = main_text.apply(lambda x: tokenizer.tokenize(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mg_rB-Ju2tJ"
      },
      "source": [
        "<h4>Removing Stopwords</h4><br>\n",
        "Remove stopwords like \"is, the, with, etc\" since they don't have usefull information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:14:54.965684Z",
          "start_time": "2020-04-26T05:14:52.151951Z"
        },
        "id": "01R47Rtru2tJ"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    words = [w for w in text if w not in stopword_list]\n",
        "    return words\n",
        "\n",
        "main_text = main_text.apply(lambda x : remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrB-ngzou2tJ"
      },
      "source": [
        "<h4>Stemming</h4><br>\n",
        "Stemming is the process of reducing a word to its word stem. For example \"Consulting\" to be \"consult\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:15:07.176162Z",
          "start_time": "2020-04-26T05:14:54.96769Z"
        },
        "id": "-iU9JiPju2tJ"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "\n",
        "def stem_update(text_list):\n",
        "    text_list_new = []\n",
        "    for word in text_list:\n",
        "        word = snowball_stemmer.stem(word)\n",
        "        text_list_new.append(word)\n",
        "    return text_list_new\n",
        "main_text = main_text.apply(stem_update)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UTQDk4-u2tJ"
      },
      "source": [
        "<h4>Drop Numbers</h4><br>\n",
        "Remove numbers from text, since numbers doesn't give much importance to get the main words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:15:08.077033Z",
          "start_time": "2020-04-26T05:15:07.178685Z"
        },
        "id": "jRGYU1p2u2tJ"
      },
      "outputs": [],
      "source": [
        "def drop_numbers(list_text):\n",
        "    list_text_new = []\n",
        "    for i in list_text:\n",
        "        if not re.search('\\d', i):\n",
        "            list_text_new.append(i)\n",
        "    return ' '.join(list_text_new)\n",
        "main_text = main_text.apply(drop_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:15:08.086043Z",
          "start_time": "2020-04-26T05:15:08.079039Z"
        },
        "id": "LLbwIkWSu2tJ"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([main_text,target],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:15:08.245018Z",
          "start_time": "2020-04-26T05:15:08.090045Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jNKVKZ1wu2tJ",
        "outputId": "1469ab56-5350-400c-bb21-c9b01c97a925"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             review_text      recommended\n",
              "0                      absolut wonder silki sexi comfort      Recommended\n",
              "1      love dres preti hapen find store glad bc never...      Recommended\n",
              "2      high hope dres reali want work initiali order ...  Not Recommended\n",
              "3      love love love jumpsuit fun flirti fabul everi...      Recommended\n",
              "4      shirt flater al due adjust front tie perfect l...      Recommended\n",
              "...                                                  ...              ...\n",
              "23481  hapi snag dres great price easi slip flater cu...      Recommended\n",
              "23482  remind matern cloth soft stretchi shini materi...      Recommended\n",
              "23483  fit wel top se never would work glad abl tri s...  Not Recommended\n",
              "23484  bought dres wede sumer cute unfortun fit perfe...      Recommended\n",
              "23485  dres love platinum feminin fit perfect easi we...      Recommended\n",
              "\n",
              "[23486 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2126b2b3-9cea-402a-9021-4fb48a1a148b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>recommended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolut wonder silki sexi comfort</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love dres preti hapen find store glad bc never...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high hope dres reali want work initiali order ...</td>\n",
              "      <td>Not Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shirt flater al due adjust front tie perfect l...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23481</th>\n",
              "      <td>hapi snag dres great price easi slip flater cu...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23482</th>\n",
              "      <td>remind matern cloth soft stretchi shini materi...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23483</th>\n",
              "      <td>fit wel top se never would work glad abl tri s...</td>\n",
              "      <td>Not Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23484</th>\n",
              "      <td>bought dres wede sumer cute unfortun fit perfe...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23485</th>\n",
              "      <td>dres love platinum feminin fit perfect easi we...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23486 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2126b2b3-9cea-402a-9021-4fb48a1a148b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2126b2b3-9cea-402a-9021-4fb48a1a148b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2126b2b3-9cea-402a-9021-4fb48a1a148b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQnaT4PXu2tK"
      },
      "source": [
        "<h2>Modelling using Multinomial Naive Bayes</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25zIwS1Mu2tK"
      },
      "source": [
        "<h4>Split the data and count the vectorize in each words</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsw6An1Ru2tK"
      },
      "source": [
        "<div style=\"text-align:justify\">The next step is to create a numerical feature vector for each document and split them into train data and test data.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:16:33.605752Z",
          "start_time": "2020-04-26T05:16:32.79512Z"
        },
        "id": "jHiUDT8vu2tK"
      },
      "outputs": [],
      "source": [
        "cv=CountVectorizer()\n",
        "\n",
        "train_data,test_data = train_test_split(df,train_size=0.8,random_state=0)\n",
        "\n",
        "X_train = cv.fit_transform(train_data['review_text'])\n",
        "y_train = train_data['recommended']\n",
        "X_test = cv.transform(test_data['review_text'])\n",
        "y_test = test_data['recommended']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QHqadEKxCQ1",
        "outputId": "c25310f0-5a90-4e48-f6e6-1621f38b1995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18788, 10578)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WHNx66QxIoe",
        "outputId": "c3d075d3-9494-4c61-cd05-1e55d0c663ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4698, 10578)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.where(y_train == \"Recommended\", 1, 0)"
      ],
      "metadata": {
        "id": "3TPbLCDWsYd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.where(y_test == \"Recommended\", 1, 0)"
      ],
      "metadata": {
        "id": "Mb_LxijFt78s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Length of Generated Reviews</h4>\n",
        "<div style=\"text-align:justify\">Normal distribution using mean and standard deviation from real data</div>"
      ],
      "metadata": {
        "id": "Af6ylZBsSdXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(np.sum(X_train, axis=1)))\n",
        "print(np.mean(np.sum(X_test, axis=1)))\n",
        "print(np.std(np.sum(X_train, axis=1)))\n",
        "print(np.std(np.sum(X_test, axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlmz8r_KOqul",
        "outputId": "0d90cdda-98dc-46b5-da0e-af524778484c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.198584202682564\n",
            "27.002979991485738\n",
            "13.760563291686998\n",
            "13.678715978231923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.count_nonzero(np.sum(X_train, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwv4KYFGg8Ei",
        "outputId": "b7755511-6103-4bfc-89ed-7592b9151d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18111"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIDSTSsWu2tL"
      },
      "source": [
        "<h4>Multinomial Naive Bayes Modelling</h4>\n",
        "<div style=\"text-align:justify\">Naive Bayes is one of algorithms method based on applying Bayes theorem.Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified. Herre below the formula of naive bayes:</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvZjdtbWu2tL"
      },
      "source": [
        "![Capture.JPG](attachment:Capture.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Fs5mLGu2tL"
      },
      "source": [
        "Where:<br>\n",
        "`P(A|B)` : measure of how often A and B are observed to occure together (posterior probability) <br>\n",
        "`P(B|A)` : measures of how often B occur in A (likelihood)<br>\n",
        "`P(A)` : measure of how often A is observed to occur in general (prior probability) <br>\n",
        "`P(B)` : measure of how often B is observed to occur in general (marginal likelihood)<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:16:33.804788Z",
          "start_time": "2020-04-26T05:16:33.618264Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPL5-cnUu2tL",
        "outputId": "db82c223-2e0a-486b-830f-d5928ba83a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-26T05:16:33.868494Z",
          "start_time": "2020-04-26T05:16:33.80729Z"
        },
        "id": "G581Pxgcu2tL"
      },
      "outputs": [],
      "source": [
        "nb_predict=nb.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nVWnhGF976Bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate synthethic data from NB model"
      ],
      "metadata": {
        "id": "sqqL8Uim7-eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb.feature_log_prob_.shape"
      ],
      "metadata": {
        "id": "iSnGiEbtxZMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf795f1e-6061-49a4-e42e-66be25233fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 10578)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb.feature_log_prob_[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfLlbMBOW7JS",
        "outputId": "2815c57a-b8ef-405b-8b73-534e2bf27ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10578,)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import multinomial"
      ],
      "metadata": {
        "id": "kt_GNhZgxlvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate training data"
      ],
      "metadata": {
        "id": "xUgExlZ66uwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "lengths = np.random.normal(loc=27, scale=14, size=18800//2)\n",
        "train_positive_lengths = np.abs((np.rint(lengths)).astype(int))"
      ],
      "metadata": {
        "id": "13g6JzupOfYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2)\n",
        "lengths = np.random.normal(loc=27, scale=14, size=18800//2)\n",
        "train_negative_lengths = np.abs((np.rint(lengths)).astype(int))"
      ],
      "metadata": {
        "id": "pAnxho78o_M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_positive_synthetic = [multinomial.rvs(length, np.exp(nb.feature_log_prob_[0])) for length in train_positive_lengths]\n",
        "X_train_negative_synthetic = [multinomial.rvs(length, np.exp(nb.feature_log_prob_[1])) for length in train_negative_lengths]"
      ],
      "metadata": {
        "id": "hOFGHMuSmMXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_positive_synthetic = np.stack(X_train_positive_synthetic)\n",
        "X_train_negative_synthetic = np.stack(X_train_negative_synthetic)"
      ],
      "metadata": {
        "id": "PPPhUCbAmSOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_synthetic = np.concatenate((X_train_positive_synthetic, X_train_negative_synthetic))\n",
        "y_train_synthetic = np.concatenate((np.ones(18800//2), np.zeros(18800//2)))"
      ],
      "metadata": {
        "id": "8TUDe9karSWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_synthetic.shape)\n",
        "print(y_train_synthetic.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBiZKFN66ypn",
        "outputId": "4c0ecb46-fb85-4148-d60e-d8ee9fa5a257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18800, 10578)\n",
            "(18800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate test data"
      ],
      "metadata": {
        "id": "JdLSp5fr65yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "lengths = np.random.normal(loc=27, scale=14, size=4700//2)\n",
        "test_positive_lengths = np.abs((np.rint(lengths)).astype(int))"
      ],
      "metadata": {
        "id": "WLcH10P57BIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(3)\n",
        "lengths = np.random.normal(loc=27, scale=14, size=4700//2)\n",
        "test_negative_lengths = np.abs((np.rint(lengths)).astype(int))"
      ],
      "metadata": {
        "id": "xehycJFq7BIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_positive_synthetic = [multinomial.rvs(length, np.exp(nb.feature_log_prob_[0])) for length in test_positive_lengths]\n",
        "X_test_negative_synthetic = [multinomial.rvs(length, np.exp(nb.feature_log_prob_[1])) for length in test_negative_lengths]"
      ],
      "metadata": {
        "id": "rDnPc9MQ7BIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_positive_synthetic = np.stack(X_test_positive_synthetic)\n",
        "X_test_negative_synthetic = np.stack(X_test_negative_synthetic)"
      ],
      "metadata": {
        "id": "uKiU59QT7BIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_synthetic = np.concatenate((X_test_positive_synthetic, X_test_negative_synthetic))\n",
        "y_test_synthetic = np.concatenate((np.ones(4700//2), np.zeros(4700//2)))"
      ],
      "metadata": {
        "id": "ml0OVJun7BIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_synthetic.shape)\n",
        "print(y_test_synthetic.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6318c927-fdcd-41d9-bd79-592faf6b3006",
        "id": "EL4RUWgi7BIw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4700, 10578)\n",
            "(4700,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform synthetic data to text"
      ],
      "metadata": {
        "id": "pCB8owGf7g5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_synthethic_text = cv.inverse_transform(X_train_synthetic)\n",
        "X_test_synthethic_text = cv.inverse_transform(X_test_synthetic)"
      ],
      "metadata": {
        "id": "zYXdrzwbrUIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_synthethic_text[0])\n",
        "print(X_test_synthethic_text[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk1Y6uUB4U0w",
        "outputId": "05456705-853b-4d8e-aa00-d9bd1f8b16fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['botom' 'boxi' 'brand' 'colect' 'color' 'either' 'fan' 'fit' 'hang'\n",
            " 'heavier' 'like' 'litl' 'love' 'lower' 'make' 'materi' 'might' 'model'\n",
            " 'motl' 'neck' 'nice' 'normal' 'noth' 'noyt' 'onlin' 'order' 'otk' 'pant'\n",
            " 'petiti' 'plane' 'price' 'qualiti' 'reali' 'right' 'se' 'serious' 'shirt'\n",
            " 'side' 'smal' 'super' 'time' 'transpa' 'volumn' 'wast' 'way' 'wear'\n",
            " 'winterth' 'would' 'xl']\n",
            "['ade' 'chest' 'god' 'golden' 'lege' 'like' 'love' 'medium' 'open' 'order'\n",
            " 'precious' 'product' 'reali' 'shape' 'sher' 'stil' 'yelow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gBiv9v6Z8tdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Synthetic Data For Training on Discriminative Models**"
      ],
      "metadata": {
        "id": "_apj29Z6lfzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train_Syn = []\n",
        "for i in X_train_synthethic_text:\n",
        "  X_Train_Syn.append(' '.join(i))\n",
        "\n",
        "X_Test_Syn = []\n",
        "for i in X_test_synthethic_text:\n",
        "  X_Test_Syn.append(' '.join(i))\n",
        "\n",
        "X_train_synthetic_text = pd.DataFrame(X_Train_Syn)\n",
        "X_test_synthetic_text = pd.DataFrame(X_Test_Syn)\n",
        "\n"
      ],
      "metadata": {
        "id": "jqhNaZmyli2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_synthetic_results = pd.DataFrame(y_train_synthetic)\n",
        "y_test_synthetic_results = pd.DataFrame(y_test_synthetic)"
      ],
      "metadata": {
        "id": "vALOIgRR2uTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to set seeds\n",
        "np.random.seed(684)\n",
        "tf.random.set_seed(684)\n",
        "random.seed(684)\n",
        "os.environ['PYTHONHASHSEED']=str(684)"
      ],
      "metadata": {
        "id": "bVJCoVoXSoTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the evaluation metrics\n",
        "def roc_auc(predictions,target):\n",
        "    \n",
        "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    return roc_auc"
      ],
      "metadata": {
        "id": "WDHjty6n699v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename Columns\n",
        "X_train_synthetic_text= X_train_synthetic_text.rename(columns={0: \"Review Text\"})\n",
        "X_test_synthetic_text= X_test_synthetic_text.rename(columns={0: \"Review Text\"})"
      ],
      "metadata": {
        "id": "YWe2ILUr3pXd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "8c61ce72-b1f7-4ea8-b755-07a1e759a46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Review Text\n",
              "0      botom boxi brand colect color either fan fit h...\n",
              "1      athletichourgla back blend color dres enough e...\n",
              "2      arm back best bodi bradshaw cloth cute debat d...\n",
              "3      also asum bag blous boxi compfi complet could ...\n",
              "4      away awkward back beauti bete bordeaux cheapn ...\n",
              "...                                                  ...\n",
              "18795  around avail bagylos bit even fit gather god g...\n",
              "18796  amaz arm beauti bit cami cut cute done flare f...\n",
              "18797  btw daughter definit fite form got holiday ned...\n",
              "18798  around backshouldersup cut flower go know ligh...\n",
              "18799        flater lot pleas returnexchang review think\n",
              "\n",
              "[18800 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80b3d0fa-0056-49c5-955c-1008a4c27520\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>botom boxi brand colect color either fan fit h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>athletichourgla back blend color dres enough e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arm back best bodi bradshaw cloth cute debat d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>also asum bag blous boxi compfi complet could ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>away awkward back beauti bete bordeaux cheapn ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18795</th>\n",
              "      <td>around avail bagylos bit even fit gather god g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18796</th>\n",
              "      <td>amaz arm beauti bit cami cut cute done flare f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18797</th>\n",
              "      <td>btw daughter definit fite form got holiday ned...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18798</th>\n",
              "      <td>around backshouldersup cut flower go know ligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18799</th>\n",
              "      <td>flater lot pleas returnexchang review think</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18800 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80b3d0fa-0056-49c5-955c-1008a4c27520')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80b3d0fa-0056-49c5-955c-1008a4c27520 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80b3d0fa-0056-49c5-955c-1008a4c27520');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "HtFE5f_dG5hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = None   \n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_words)\n",
        "tokenizer.fit_on_texts(X_train_synthetic_text['Review Text'].tolist() + X_test_synthetic_text['Review Text'].tolist())  \n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_synthetic_text['Review Text'].tolist())\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_synthetic_text['Review Text'].tolist())\n",
        "\n",
        "max_len = max([len(x) for x in X_train_seq])\n",
        "\n",
        "X_train_pad_syn = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad_syn = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "# Output shapes\n",
        "print(\"\\nPadded training shape:\", X_train_pad_syn.shape)\n",
        "print(\"\\nPadded test shape:\", X_test_pad_syn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUzAwVqY3k9N",
        "outputId": "26507393-9897-4963-d078-bec166ba6238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padded training shape: (18800, 75)\n",
            "\n",
            "Padded test shape: (4700, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN METHOD ON SYNTHETIC**"
      ],
      "metadata": {
        "id": "FC15EdAc7X_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                    50,     \n",
        "                    input_length=max_len))\n",
        "model.add(SimpleRNN(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8FKw5RG3Q7i",
        "outputId": "149bef18-6daf-4769-8cfd-d2da36b58217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 75, 50)            526200    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100)               15100     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 541,401\n",
            "Trainable params: 541,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "model.fit(X_train_pad_syn, y_train_synthetic, epochs=5, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av-nkdtc42hK",
        "outputId": "4447e9a8-65a1-42ec-e85c-6e7d8384cdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "37/37 [==============================] - 8s 183ms/step - loss: 0.6721 - accuracy: 0.5889\n",
            "Epoch 2/5\n",
            "37/37 [==============================] - 7s 176ms/step - loss: 0.4800 - accuracy: 0.7959\n",
            "Epoch 3/5\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.3199 - accuracy: 0.8693\n",
            "Epoch 4/5\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.2234 - accuracy: 0.9110\n",
            "Epoch 5/5\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.2384 - accuracy: 0.9176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf91179e80>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.predict(X_test_pad_syn)\n",
        "print(\"AUC: %.2f%%\" % (roc_auc(scores,y_test_synthetic_results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcWuGfXO6QV3",
        "outputId": "94fc3e6d-76fc-4e2f-9fb5-fdd555e5cd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147/147 [==============================] - 1s 8ms/step\n",
            "AUC: 0.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM METHOD WITH SYTHETIC**"
      ],
      "metadata": {
        "id": "q29RYCoG7c-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(len(word_index) + 1,\n",
        "                    50,     # embeds it in a 50-dimensional vector\n",
        "                    input_length=max_len))\n",
        "\n",
        "model2.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    \n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VNxyUEb7g8i",
        "outputId": "d42703f8-2200-4c24-f897-8909b007ed58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 75, 50)            526200    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               60400     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 586,701\n",
            "Trainable params: 586,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "\n",
        "model2.fit(X_train_pad_syn, y_train_synthetic, epochs=5, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HAUq9j67kyW",
        "outputId": "b0fd41fc-4b2e-4a94-a676-a83b8b78b155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "37/37 [==============================] - 42s 1s/step - loss: 0.6475 - accuracy: 0.6442\n",
            "Epoch 2/5\n",
            "37/37 [==============================] - 36s 972ms/step - loss: 0.4406 - accuracy: 0.8306\n",
            "Epoch 3/5\n",
            "37/37 [==============================] - 36s 969ms/step - loss: 0.2926 - accuracy: 0.8803\n",
            "Epoch 4/5\n",
            "37/37 [==============================] - 36s 971ms/step - loss: 0.2207 - accuracy: 0.9039\n",
            "Epoch 5/5\n",
            "37/37 [==============================] - 36s 975ms/step - loss: 0.1726 - accuracy: 0.9248\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf90772040>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model2.predict(X_test_pad_syn)\n",
        "print(\"AUC: %.2f%%\" % (roc_auc(scores,y_test_synthetic_results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_UenaAG8tR6",
        "outputId": "7bb88958-ee21-4185-a81b-bd2a09c4cd2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147/147 [==============================] - 4s 27ms/step\n",
            "AUC: 0.96%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}